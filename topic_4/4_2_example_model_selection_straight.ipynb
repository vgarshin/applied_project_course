{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separated-repair",
   "metadata": {},
   "source": [
    "# Applied Project in Big Data on Industrial Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-convention",
   "metadata": {},
   "source": [
    "## MODELS SELECTION TECHNIQUES\n",
    "## Part II. Straight way to organize a project and track experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-immune",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer, \n",
    "    CountVectorizer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    train_test_split,\n",
    "    StratifiedKFold\n",
    ")\n",
    "pd.set_option('display.max_columns', None)\n",
    "N_CORES = min(\n",
    "    multiprocessing.cpu_count(), \n",
    "    int(float(os.environ['CPU_LIMIT']))\n",
    ")\n",
    "print('cores:', N_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-shoot",
   "metadata": {},
   "source": [
    "### 2. Create config and place to store artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "VER = 'v1'\n",
    "CONFIG = {\n",
    "    'version': VER,\n",
    "    'start_time': str(datetime.datetime.fromtimestamp(start_time)),\n",
    "    'sample_size': 1000,\n",
    "    'ngram_range': (1, 1), \n",
    "    'max_df': .95, \n",
    "    'min_df': 10,\n",
    "    'clf': 'RandomForestClassifier',\n",
    "    'folds': 8,\n",
    "    'seed': 2021,\n",
    "    'n_iters': 50,\n",
    "    'comments': ''\n",
    "}\n",
    "MDLS_PATH = f'./models_{VER}'\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/config.json', 'w') as file:\n",
    "    json.dump(CONFIG, file)\n",
    "    \n",
    "def seed_all(seed):\n",
    "    \"\"\"\n",
    "    Sometimes it is useful to nail all randomness\n",
    "    and fix all random seeds for reproducibility.\n",
    "    \n",
    "    This function fixes all random seeds for current pipline, \n",
    "    but it could be extended e.g. for Tensorflow library \n",
    "    you may want to add `tf.random.set_seed(seed)` in the code.\n",
    "    \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-virtue",
   "metadata": {},
   "source": [
    "### 2. Create a small dataset for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_white_en.csv')\n",
    "df = df.sample(CONFIG['sample_size']).reset_index()\n",
    "del df['index']\n",
    "df['label'] = 0\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv('data_black_en.csv')\n",
    "df_tmp = df_tmp.sample(CONFIG['sample_size']).reset_index()\n",
    "del df_tmp['index']\n",
    "df_tmp['label'] = 1\n",
    "print(df_tmp.shape)\n",
    "display(df_tmp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df_tmp)\n",
    "df.reset_index(inplace=True)\n",
    "del df['index']\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary\n",
    "save_data_path = f'{MDLS_PATH}/data_{CONFIG[\"version\"]}.csv'\n",
    "df.to_csv(save_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-elements",
   "metadata": {},
   "source": [
    "### 3. Modelling with save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(data, vectorizer):\n",
    "    print('total texts:', len(data))\n",
    "    features = vectorizer.fit_transform(data)\n",
    "    print(\n",
    "        'features shape:', features.shape, \n",
    "        'max:', np.max(features), \n",
    "        'min:', np.min(features)\n",
    "    )\n",
    "    return features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_model(X, y, \n",
    "                    folds, clf,\n",
    "                    vectorizer, ngram_range=(1, 1), \n",
    "                    max_df=.2, min_df=8, seed=2022):\n",
    "    scores = {}\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "    for fold, (train_idxs, test_idxs) in enumerate(skf.split(X, y)):\n",
    "        \n",
    "        # train model\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "        y_train, y_test = y.iloc[train_idxs], y.iloc[test_idxs]\n",
    "        X_train, vectorizer = text_features(\n",
    "            X_train, \n",
    "            vectorizer=vectorizer\n",
    "        )\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # saving models\n",
    "        # more about https://scikit-learn.org/stable/model_persistence.html\n",
    "        # NOTE - not only model, but vectorizer too!\n",
    "        \n",
    "        file_name = f'{MDLS_PATH}/model_fold_{fold}.joblib'\n",
    "        dump(clf, file_name)\n",
    "        print('saved to', file_name)\n",
    "        file_name = f'{MDLS_PATH}/vectorizer_fold_{fold}.joblib'\n",
    "        dump(vectorizer, file_name)\n",
    "        print('saved to', file_name)\n",
    "        \n",
    "        # metrics\n",
    "        \n",
    "        y_score = clf.predict_proba(X_test)\n",
    "        roc_auc_score_ = roc_auc_score(y_test, y_score[:, 1])\n",
    "        roc_auc_scores.append(roc_auc_score)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        f1_score_ = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1_score_)\n",
    "        msg = f'fold {fold} - val ROC-AUC score: {roc_auc_score_:.2f}, val f1-score: {f1_score_:.2f}'\n",
    "        print(msg)\n",
    "        \n",
    "        scores[f'fold {fold}'] = {\n",
    "            'roc_auc_scores': roc_auc_scores,\n",
    "            'f1_scores': f1_scores\n",
    "        }\n",
    "        \n",
    "        # logging (if needed)\n",
    "        # read about logging for production cases here https://docs.python.org/3/library/logging.html\n",
    "        \n",
    "        log_file_name = f'{MDLS_PATH}/model_{CONFIG[\"version\"]}.log'\n",
    "        log_string = f'{str(datetime.datetime.fromtimestamp(time.time()))} - {msg}\\n'\n",
    "        with open(log_file_name, 'a') as file:\n",
    "            file.write(log_string)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(\n",
    "    ngram_range=CONFIG['ngram_range'], \n",
    "    max_df=CONFIG['max_df'], \n",
    "    min_df=CONFIG['min_df']\n",
    ")\n",
    "if CONFIG['clf'] == 'RandomForestClassifier':\n",
    "    clf = RandomForestClassifier(n_estimators=CONFIG['n_iters']) \n",
    "else:\n",
    "    clf = LogisticRegression()\n",
    "scores = cross_val_model(\n",
    "    X=df['proc'], \n",
    "    y=df['label'], \n",
    "    folds=CONFIG['folds'], \n",
    "    clf=clf,\n",
    "    vectorizer=vectorizer,\n",
    "    seed=CONFIG['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-finding",
   "metadata": {},
   "source": [
    "### 4. Not only save models but get them back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 'v0'\n",
    "with open(f'{MDLS_PATH}/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "vectorizers = []\n",
    "for fold in range(config['folds']):\n",
    "    file_name = f'{MDLS_PATH}/model_fold_{fold}.joblib'\n",
    "    model = load(file_name)\n",
    "    models.append(model)\n",
    "    \n",
    "    file_name = f'{MDLS_PATH}/vectorizer_fold_{fold}.joblib'\n",
    "    vectorizer = load(file_name)\n",
    "    vectorizers.append(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv('data_black_en.csv')\n",
    "df_tmp = df_tmp.sample(100).reset_index()\n",
    "del df_tmp['index']\n",
    "df_tmp['label'] = 1\n",
    "print(df_tmp.shape)\n",
    "display(df_tmp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectorizer = vectorizers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_vectorizer.transform(df_tmp['proc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = test_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['predictions'] = y_score[:, 1]\n",
    "print(df_tmp.shape)\n",
    "display(df_tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-apparatus",
   "metadata": {},
   "source": [
    "### 5. Way of Jedi datascientist - make a predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jedi_predictions(data, models, vectorizers):\n",
    "    preds = []\n",
    "    for m, v in zip(models, vectorizers):\n",
    "        data_ = v.transform(data)\n",
    "        y_score = m.predict_proba(data_)\n",
    "        preds.append(y_score)\n",
    "    return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = jedi_predictions(df_tmp['proc'], models, vectorizers)\n",
    "y_score[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['predictions'] = y_score[:, 1]\n",
    "print(df_tmp.shape)\n",
    "display(df_tmp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-replication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
